{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0ffdf2e",
   "metadata": {},
   "source": [
    "# INSY336 Social Speculation for Harnessing Reddit to Forecast Bitcoin Fluctuations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f27af1",
   "metadata": {},
   "source": [
    "## ETL Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fe2a9268",
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpers functions\n",
    "import requests\n",
    "import requests.auth\n",
    "import datetime\n",
    "\n",
    "\n",
    "def convert_date(date: float)->str:\n",
    "    \"\"\"Convert numeric date to string date (YYYY-MM-DD)\n",
    "    \n",
    "    Args:\n",
    "        date (float): date in numeric format\n",
    "    \n",
    "    Returns:\n",
    "        date (str): date in YYYY-MM-DD format\n",
    "    \"\"\"\n",
    "    \n",
    "    date_time = datetime.datetime.fromtimestamp(date)\n",
    "    return date_time.strftime(\"%Y-%m-%d\")\n",
    "\n",
    "def get_authheaders(client_id: str, client_secret: str, username: str, password: str)->dict:\n",
    "    \"\"\"Get authorization headers from Reddit API\n",
    "    \n",
    "    Args:\n",
    "        client_id (str): client id from Reddit API\n",
    "        client_secret (str): client secret from Reddit API\n",
    "        username (str): Reddit username\n",
    "        password (str): Reddit password\n",
    "\n",
    "    Returns:\n",
    "        dict: authorization headers\n",
    "    \"\"\"\n",
    "\n",
    "    client_auth = requests.auth.HTTPBasicAuth(client_id, client_secret)\n",
    "    post_data = {\"grant_type\": \"password\", \"username\": username, \"password\": password}\n",
    "    headers = {\"User-Agent\": f\"ChangeMeClient/0.1 by {username}\"}\n",
    "\n",
    "    response = requests.post(\"https://www.reddit.com/api/v1/access_token\", auth=client_auth, data=post_data, headers=headers)\n",
    "\n",
    "    token = response.json()['access_token']\n",
    "    type = response.json()['token_type']\n",
    "    auth_str = f\"{type} {token}\"\n",
    "\n",
    "    return {\"Authorization\": auth_str, \"User-Agent\": f\"ChangeMeClient/0.1 by {username}\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8145e14d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing needed packages\n",
    "import requests\n",
    "from textblob import TextBlob\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "32e043c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the authentication headers\n",
    "from credentials import client_id, client_secret, username, password\n",
    "\n",
    "headers = get_authheaders(client_id, client_secret, username, password)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "897dc058",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a database connection to the SQLite database file reddit.db using the sqlite3 library\n",
    "conn = sqlite3.connect('reddit.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85470d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_table(conn: sqlite3.Connection, table_name: str, schema: str)->None:\n",
    "    \"\"\"Drop and Create table in database\n",
    "\n",
    "    Difficulty: Easy\n",
    "    \n",
    "    Args:\n",
    "        conn (sqlite3.Connection): connection to database\n",
    "        table_name (str): table name\n",
    "        schema (str): table schema\n",
    "\n",
    "    Returns:    \n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    # drop table if exists\n",
    "    query_drop = f\"drop table if exists {table_name}\"\n",
    "    conn.execute(query_drop)\n",
    "    # create table\n",
    "    query_create = f\"create table {table_name}({schema})\"\n",
    "    conn.execute(query_create)\n",
    "    # commit change\n",
    "    conn.commit()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecc8b155",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema_posts = \"\"\"\n",
    "    id varchar(10),\n",
    "    title text,\n",
    "    score int,\n",
    "    ups int,\n",
    "    downs int,\n",
    "    upvote_ratio float,\n",
    "    url text,\n",
    "    num_comments int,\n",
    "    created float,\n",
    "    body text,\n",
    "    sentiment float,\n",
    "    subjectivity float,\n",
    "    primary key (id)\n",
    "\"\"\"\n",
    "\n",
    "create_table(conn, \"posts\", schema_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4cbbcb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_reddit(headers: dict, subreddit: str, after: str=None, limit: int=100)->dict:\n",
    "    \"\"\"Get new posts from a subreddit using Reddit API\n",
    "\n",
    "    Difficulty: Medium\n",
    "    \n",
    "    Args:\n",
    "        headers (dict): authorization headers (must be passed along to API)\n",
    "        subreddit (str): subreddit name to get posts from\n",
    "        after (str): after post id (see Reddit API documentation)\n",
    "        limit (int): number of posts to get (max 100)\n",
    "    \n",
    "    Returns:\n",
    "        json response from Reddit API (dict)\n",
    "    \"\"\"\n",
    "\n",
    "    url = f'https://oauth.reddit.com/r/{subreddit}/new'\n",
    "\n",
    "    params = {\n",
    "        'after' : after,\n",
    "        'limit' : limit\n",
    "    }\n",
    "\n",
    "    output = requests.get(url, headers = headers, params = params)\n",
    "\n",
    "    return output.json() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a57fc36",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(text: str)->float:\n",
    "    \"\"\"Get sentiment score from text.\n",
    "    The function uses TextBlob to calculate the sentiment score of the text if the text is not empty.\n",
    "\n",
    "    Difficulty: Medium\n",
    "    \n",
    "    Args:\n",
    "        text (str): text to analyze\n",
    "\n",
    "    Returns:\n",
    "        sentiment score (float)\n",
    "    \"\"\"\n",
    "\n",
    "    if len(text) != 0:\n",
    "        blob = TextBlob(text)\n",
    "        return blob.sentiment.polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e97980ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subjectivity(text: str)->float:\n",
    "    \"\"\"Get subjectivity score from text\n",
    "    The function uses TextBlob to calculate the subjectivity score of the text if the text is not empty.\n",
    "\n",
    "    Difficulty: Medium\n",
    "\n",
    "    Args:\n",
    "        text (str): text to analyze\n",
    "\n",
    "    Returns:\n",
    "        subjectivity score (float)    \n",
    "    \"\"\"\n",
    "\n",
    "    if len(text) != 0:\n",
    "        blob = TextBlob(text)\n",
    "        return blob.sentiment.subjectivity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f0fb72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_reddit(response: dict)->list:\n",
    "    \"\"\"Prepare posts for insert into database from Reddit API response and return list of dicts.\n",
    "    The output must match the schema of the table, including sentiment and subjectivity scores calculated from the body of the post.\n",
    "    You may want to use the convert_date, get_sentiment, and get_subjectivity functions to process the data. You don't need to define convert_date() as it is already defined in helpers.py and imported above.\n",
    "\n",
    "    Difficulty: Medium\n",
    "\n",
    "    Args:\n",
    "        response (dict): json response from Reddit API\n",
    "\n",
    "    Returns:\n",
    "        list of dicts\n",
    "    \"\"\"\n",
    "\n",
    "    transformed_data = []    \n",
    "    for element in response['data']['children']:\n",
    "        data = element['data']\n",
    "        id = data['id']\n",
    "        title = data['title']\n",
    "        score = data['score']\n",
    "        ups = data['ups']\n",
    "        downs = data['downs']\n",
    "        upvote_ratio = data['upvote_ratio']\n",
    "        url = data['url']\n",
    "        num_comments = data['num_comments']\n",
    "        created = convert_date(data['created'])\n",
    "        body = data['selftext']\n",
    "        sentiment = get_sentiment(body)\n",
    "        subjectivity = get_subjectivity(body)\n",
    "        record = {'id':id,'title':title,'score':score,'ups':ups,'downs':downs,'upvote_ratio':upvote_ratio,'url':url,'num_comments':num_comments,'created':created,'body':body,'sentiment':sentiment,'subjectivity':subjectivity}\n",
    "        transformed_data.append(record)\n",
    "\n",
    "    return transformed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2fef940",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_reddit(conn: sqlite3.Connection, data: list)->None:\n",
    "    \"\"\"Insert data into database. \n",
    "    The function takes a list of dicts as an argument, constructs insert queries with placeholders for the values, and executes the queries. The target table posts must already exist in the database.\n",
    "\n",
    "    Difficulty: Easy\n",
    "\n",
    "    Args:\n",
    "        conn (sqlite3.Connection): connection to database\n",
    "        data (list): list of dicts to insert into database\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    for record in data:\n",
    "        query = f\"insert into posts values (:id,:title,:score,:ups,:downs,:upvote_ratio,:url,:num_comments,:created,:body,:sentiment,:subjectivity)\"\n",
    "        conn.execute(query, record)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f1f87620",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reddit_etl(conn: sqlite3.Connection, headers: dict, subreddit: str, n: int=6, limit: int=100)->None:\n",
    "    \"\"\"Extract, transform, and load reddit data into database\n",
    "    The reddit API returns a maximum of 100 posts per request. To get more than 100 posts, you must make multiple requests with the after parameter which points to the last post id of the previous request.\n",
    "    Do not set n to a value greater than 6 as the Reddit API may return duplicate posts.\n",
    "\n",
    "    Difficulty: Hard\n",
    "    \n",
    "    Args:\n",
    "        conn (sqlite3.Connection): connection to database\n",
    "        headers (dict): authorization headers (must be passed along to API)\n",
    "        subreddit (str): subreddit name to get posts from\n",
    "        n (int): number of requests to make to Reddit API\n",
    "        limit (int): number of posts to get per request (max 100)\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    response = extract_reddit(headers, subreddit, limit=limit)\n",
    "    data = transform_reddit(response)\n",
    "    load_reddit(conn,data)\n",
    "    for iters in range(1,n):\n",
    "        response = extract_reddit(headers, subreddit, response['data']['after'], limit)\n",
    "        data = transform_reddit(response)\n",
    "        load_reddit(conn, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d66694a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ETL pipeline for the crypto data\n",
    "schema_crypto = \"\"\"\n",
    "    symbol varchar(10),\n",
    "    date varchar(10),\n",
    "    close float,\n",
    "    primary key(symbol, date)\n",
    "\"\"\"\n",
    "\n",
    "create_table(conn, 'crypto', schema_crypto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d2efe21",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_crypto(symbol: str, key: str, market='EUR')->dict:\n",
    "    \"\"\"Get crypto prices from AlphaVantage API\n",
    "\n",
    "    Difficulty: Easy\n",
    "\n",
    "    Args:\n",
    "        symbol (str): crypto symbol (e.g. BTC)\n",
    "        key (str): API key\n",
    "        market (str): market\n",
    "\n",
    "    Returns:\n",
    "        json response from AlphaVantage API (dict)    \n",
    "    \"\"\"\n",
    "    url = 'https://www.alphavantage.co/query'\n",
    "\n",
    "    params = {\n",
    "        'function': 'DIGITAL_CURRENCY_DAILY',\n",
    "        'symbol': symbol,\n",
    "        'market': market,\n",
    "        'apikey': key\n",
    "    }\n",
    "\n",
    "    output = requests.get(url, params)\n",
    "\n",
    "    return output.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "46527f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Meta Data', 'Time Series (Digital Currency Daily)'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from credentials import key\n",
    "\n",
    "response = extract_crypto(\"BTC\", key, market='EUR')\n",
    "response.keys()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d1883773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'1. open': '61803.03000000',\n",
       " '2. high': '63574.05000000',\n",
       " '3. low': '61629.62000000',\n",
       " '4. close': '62976.58000000',\n",
       " '5. volume': '313.65572182'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response['Time Series (Digital Currency Daily)']['2024-10-24']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7107880a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_crypto(response: dict)->list:\n",
    "    \"\"\"Prepare crypto response for insert into database and return list of dicts.\n",
    "    The output must match the schema of the table.\n",
    "\n",
    "    Difficulty: Easy\n",
    "    \n",
    "    Args:\n",
    "        response (dict): json response from AlphaVantage API\n",
    "\n",
    "    Returns:\n",
    "        list of dicts\n",
    "    \"\"\"\n",
    "    symbol = response['Meta Data']['2. Digital Currency Code']\n",
    "    raw_data = response['Time Series (Digital Currency Daily)']\n",
    "    data_output = []\n",
    "    for date, value in raw_data.items():\n",
    "        record = {'symbol': symbol,'date': date, 'close': value['4. close']}\n",
    "        data_output.append(record)\n",
    "\n",
    "    return data_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c937274",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_crypto(conn: sqlite3.Connection, data: list)->None:\n",
    "    \"\"\"Insert data into database\n",
    "    The function takes a list of dicts as an argument, constructs insert queries with placeholders for the values, and executes the queries. The target table crypto must already exist in the database.\n",
    "\n",
    "    Difficulty: Easy\n",
    "    \n",
    "    Args:\n",
    "        conn (sqlite3.Connection): connection to database\n",
    "        data (list): list of dicts to insert into database\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    query = 'insert into crypto values (:symbol, :date, :close)'\n",
    "    conn.executemany(query, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9a6efcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def crypto_etl(conn: sqlite3.Connection, symbol: str, key: str, market: str='EUR'):\n",
    "    \"\"\"Extract, transform, and load crypto data into database\n",
    "\n",
    "    Difficulty: Easy\n",
    "    \n",
    "    Args:\n",
    "        conn (sqlite3.Connection): connection to database\n",
    "        symbol (str): crypto symbol (e.g. BTC)\n",
    "        key (str): API key\n",
    "        market (str): market\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    response = extract_crypto(symbol, key, market)\n",
    "    if len(response) != 0:\n",
    "        data = transform_crypto(response)\n",
    "\n",
    "    load_crypto(conn, data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ab2d76bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fa7ec26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the database\n",
    "conn = sqlite3.connect(\"reddit.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b90c3132",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create table\n",
    "create_table(conn, \"posts\", schema_posts)\n",
    "create_table(conn, 'crypto', schema_crypto)\n",
    "\n",
    "# run etl to insert data\n",
    "subreddit = 'btc'\n",
    "reddit_etl(conn, headers, subreddit, n=8)\n",
    "symbol = 'BTC'\n",
    "crypto_etl(conn, symbol, key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe85790",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close connection\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
